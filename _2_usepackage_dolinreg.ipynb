{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423b768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "true_w = torch.tensor([2,-3.4])\n",
    "true_b = 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4dd9a",
   "metadata": {},
   "source": [
    "同理的人造数据生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f36f53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w,b,num_examples):\n",
    "    X = torch.normal(0,1,(num_examples,len(w)))#行数为样本数，列数为w的行数的矩阵\n",
    "    y = torch.matmul(X,w) + b#做X矩阵（二维张量）和w向量（一维张量）的乘法，然后加上b，这里根据tensor的运算特性，b虽然只是一个值，但是会加到算出的一维张量的每一个元素上\n",
    "    y += torch.normal(0,0.01,y.shape)#加上噪声\n",
    "    return X,y.reshape((-1,1))#把y重新变成列向量，这里是二维张量，多行一列\n",
    "\n",
    "features, labels = synthetic_data(true_w,true_b,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844f1b3",
   "metadata": {},
   "source": [
    "用torch自带的data.TensorDataset类（也就是张量数据集类）以及自带的data.DataLoader迭代器来构造并输出一个数据集迭代器，每次迭代输出一个小批次的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8dfafb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.2630, -1.7926],\n",
       "         [-0.7948, -0.4161],\n",
       "         [ 0.6755,  0.9307],\n",
       "         [ 1.2700,  0.1382],\n",
       "         [-0.9338, -1.1272],\n",
       "         [-0.5846,  0.0662],\n",
       "         [ 0.3538,  0.3069],\n",
       "         [ 0.7527,  1.9665],\n",
       "         [-1.8902, -0.8176],\n",
       "         [ 2.5099,  0.4185]]),\n",
       " tensor([[ 7.7929],\n",
       "         [ 4.0276],\n",
       "         [ 2.3925],\n",
       "         [ 6.2793],\n",
       "         [ 6.1634],\n",
       "         [ 2.8137],\n",
       "         [ 3.8615],\n",
       "         [-0.9818],\n",
       "         [ 3.2019],\n",
       "         [ 7.7827]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    '''构造并输出一个数据迭代器'''\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features,labels),batch_size)\n",
    "\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d0fbb",
   "metadata": {},
   "source": [
    "定义线性模型，这里直接用torch自带的线性模型nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f162397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "net = nn.Sequential(nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44ce40",
   "metadata": {},
   "source": [
    "初始化模型参数（这里的\\[0\\]）是因为上一段中用了nn.Sequential意思是把这个模型放到一个模型序列中，所以调用要调用第0层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe03731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0,0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2be04",
   "metadata": {},
   "source": [
    "用模型自己定义好的损失函数，和我们之前写的损失函数没什么区别，只是它已经求过和了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc95ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786e493",
   "metadata": {},
   "source": [
    "从torch自带的优化算法中选择SGD算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de23653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03affb83",
   "metadata": {},
   "source": [
    "训练过程，和上一个没什么区别，只是这次用torch自带的工具封装了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "210846ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 0.000254\n",
      "epoch 2,loss 0.000109\n",
      "epoch 3,loss 0.000110\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter:\n",
    "        l = loss(net(X),y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features),labels)\n",
    "    print(f'epoch {epoch + 1},loss {l.detach():f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
